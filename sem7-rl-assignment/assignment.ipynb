{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4   # number of actions\n",
    "Actions = {0 : ('L', (0, -1)),\n",
    "     1 : ('R', (0, 1)), \n",
    "     2 : ('U', (-1, 0)), \n",
    "     3 : ('D', (1, 0))}\n",
    "\n",
    "def state2idx(s, n):\n",
    "    return divmod(s, n)\n",
    "\n",
    "def idx2state(idx, n):\n",
    "    return idx[0]*n + idx[1]\n",
    "\n",
    "def nextState(s, a, n):\n",
    "    '''\n",
    "        Args:\n",
    "            s : current state\n",
    "            a : action taken\n",
    "        \n",
    "        Return:\n",
    "            s_next : next state\n",
    "    '''\n",
    "    s_next = -1\n",
    "\n",
    "    s_idx = state2idx(s, n)\n",
    "    delta = Actions[a][1]\n",
    "    s_next_idx = (s_idx[0] + delta[0], s_idx[1] + delta[1])\n",
    "\n",
    "    if 0 <= s_next_idx[0] < n and 0 <= s_next_idx[1] < n:\n",
    "        s_next = idx2state(s_next_idx, n)\n",
    "    \n",
    "    return s_next\n",
    "\n",
    "def createMDP(n, psucc, rlo=-3, rhi=3):\n",
    "    '''\n",
    "        Args:\n",
    "            n : grid size\n",
    "            psucc : probability of success of an action\n",
    "\n",
    "        Return:\n",
    "            P : probability transition matrix for each action\n",
    "            R : reward mapping for each state\n",
    "    '''\n",
    "\n",
    "    P = np.zeros((k, n*n, n*n), dtype=np.float)\n",
    "\n",
    "    # for each action\n",
    "    for a in range(k):\n",
    "        # for each state\n",
    "        for s in range(n*n):\n",
    "            s_next = nextState(s, a, n)\n",
    "            if s_next != -1:\n",
    "                P[a, s, s_next] = psucc\n",
    "                P[a, s, s] = 1 - psucc\n",
    "            else:\n",
    "                P[a, s, s] = 1\n",
    "\n",
    "    R = np.random.randint(rlo, rhi, size=(n*n))\n",
    "\n",
    "    return (P, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[[1.   0.   0.   ... 0.   0.   0.  ]\n  [0.75 0.25 0.   ... 0.   0.   0.  ]\n  [0.   0.75 0.25 ... 0.   0.   0.  ]\n  ...\n  [0.   0.   0.   ... 0.25 0.   0.  ]\n  [0.   0.   0.   ... 0.75 0.25 0.  ]\n  [0.   0.   0.   ... 0.   0.75 0.25]]\n\n [[0.25 0.75 0.   ... 0.   0.   0.  ]\n  [0.   0.25 0.75 ... 0.   0.   0.  ]\n  [0.   0.   0.25 ... 0.   0.   0.  ]\n  ...\n  [0.   0.   0.   ... 0.25 0.75 0.  ]\n  [0.   0.   0.   ... 0.   0.25 0.75]\n  [0.   0.   0.   ... 0.   0.   1.  ]]\n\n [[1.   0.   0.   ... 0.   0.   0.  ]\n  [0.   1.   0.   ... 0.   0.   0.  ]\n  [0.   0.   1.   ... 0.   0.   0.  ]\n  ...\n  [0.   0.   0.   ... 0.25 0.   0.  ]\n  [0.   0.   0.   ... 0.   0.25 0.  ]\n  [0.   0.   0.   ... 0.   0.   0.25]]\n\n [[0.25 0.   0.   ... 0.   0.   0.  ]\n  [0.   0.25 0.   ... 0.   0.   0.  ]\n  [0.   0.   0.25 ... 0.   0.   0.  ]\n  ...\n  [0.   0.   0.   ... 1.   0.   0.  ]\n  [0.   0.   0.   ... 0.   1.   0.  ]\n  [0.   0.   0.   ... 0.   0.   1.  ]]] [-2 -2  0 -1  2  0 -2 -1  1  0 -3  2 -3  2  1  2]\n"
    }
   ],
   "source": [
    "(P, R) = createMDP(4 , 0.75)\n",
    "print(P, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandSDP(num_states, num_actions):\n",
    "    '''\n",
    "        Generates a stationary deterministic policy\n",
    "    '''\n",
    "    return np.random.randint(num_actions, size=num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1 1 2 3 3 1 0 2 3 1 0 2 3 3 1 2]\n"
    }
   ],
   "source": [
    "print(genRandSDP(4*4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    "    \"\"\"Base class for exceptions in this module.\"\"\"\n",
    "    pass\n",
    "\n",
    "def gaussElimination(A, b):\n",
    "    '''\n",
    "        A : numpy array of shape : (n * n)\n",
    "        b : numpy array of shape : (n,)\n",
    "        Solve equation Ax = b where A is matrix of size n * n and b is a vector of size n\n",
    "        Return: a vector x which is the solution of this equation\n",
    "    '''\n",
    "    if A.ndim != 2 or A.shape[0] != A.shape[1]:\n",
    "        raise Error('A must be a square matrix')\n",
    "    \n",
    "    elif b.ndim != 1 or A.shape[1] != b.shape[0]:\n",
    "        raise Error('b must be a vector with appropriate size')\n",
    "\n",
    "    # applying forward elimination\n",
    "    A = copy.deepcopy(A).astype(np.float)\n",
    "    b = copy.deepcopy(b).astype(np.float)\n",
    "\n",
    "    n = b.shape[0]\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    #### forward elimination ####\n",
    "\n",
    "    # loop over all rows in A, except last\n",
    "    for k in range(n-1):\n",
    "        # loop over all rows below the diagonal position (k, k)\n",
    "        for i in range(k+1, n):\n",
    "            # compute multiplier for row i and column k\n",
    "            m_ik = A[i, k] / A[k, k] \n",
    "            # update b[i]\n",
    "            b[i] -= m_ik * b[k]\n",
    "            # loop over all the columns to the right of the diagonal position (k, k)\n",
    "            for j in range(k+1, n):\n",
    "                # update the value\n",
    "                A[i, j] -= m_ik * A[k, j]\n",
    "\n",
    "    #### back substitution ####\n",
    "\n",
    "    x[n-1] = b[n-1] / A[n-1, n-1]\n",
    "\n",
    "    for i in range(n-2, -1, -1):\n",
    "        s = 0\n",
    "        for j in range(i+1, n):\n",
    "            s += A[i, j] * x[j]\n",
    "\n",
    "        x[i] = (b[i] - s) / A[i,i]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ 1. -2. -2.]\n"
    }
   ],
   "source": [
    "A = np.array([[3, 2, -1], [2, -2, 4] , [-1, 0.5, -1]])\n",
    "b = np.array([1, -2, 0])\n",
    "# Ax = b ==> x = [1, -2, -2]\n",
    "\n",
    "print(gaussElimination(A, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueViaInv(P, gamma, R):\n",
    "    '''\n",
    "        Args:\n",
    "            P : probability transition matrix\n",
    "            gamma : discount faactor\n",
    "            R : reward map\n",
    "        Return:\n",
    "            Solution of equation => (I - gamma * P)V = R\n",
    "            where V is the value function\n",
    "    '''\n",
    "    n = R.shape[0]\n",
    "    I = np.eye(n)\n",
    "\n",
    "    A = (I - gamma * P)\n",
    "    b = R\n",
    "\n",
    "    return gaussElimination(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbTranMat(Pk, u):\n",
    "    '''\n",
    "        Args:\n",
    "            Pk : Probability transition matrix for each action\n",
    "            u : deterministic policy\n",
    "        Return:\n",
    "            P : Porbability transition matrix for the given policy\n",
    "    '''\n",
    "    num_states = u.shape[0]\n",
    "    P = np.zeros((num_states, num_states))\n",
    "    for s in range(num_states):\n",
    "        a = u[s]\n",
    "        P[s, :] = Pk[a, s, :]\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneStep(V, R, P, gamma):\n",
    "    '''\n",
    "        Args:\n",
    "            V : current value function\n",
    "            R : reward mapping\n",
    "            P : probability transition matrix\n",
    "            gamma : dicount factor\n",
    "        Return: Calculates the next update for the value function\n",
    "    '''\n",
    "    return (R + gamma * np.dot(P, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueEval(R, P, gamma, eps=1e-6):\n",
    "    '''\n",
    "        Args:\n",
    "            R : reward mapping\n",
    "            P : probability transition matrix\n",
    "            gamma : discount factor\n",
    "            eps : precision\n",
    "        Return:\n",
    "            V : performs the policy evaluation to compute the \n",
    "                value function for the given MDP\n",
    "    '''\n",
    "\n",
    "    V = np.zeros(R.shape[0], dtype=np.float)\n",
    "    V_next = oneStep(V, R, P, gamma)\n",
    "\n",
    "    while np.linalg.norm(V_next - V, np.inf) > eps:\n",
    "        V = V_next\n",
    "        V_next = oneStep(V, R, P, gamma)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Probability Transition Matrix:\n [[1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n [0.55 0.45 0.   0.   0.   0.   0.   0.   0.  ]\n [0.   0.   1.   0.   0.   0.   0.   0.   0.  ]\n [0.   0.   0.   0.45 0.   0.   0.55 0.   0.  ]\n [0.   0.55 0.   0.   0.45 0.   0.   0.   0.  ]\n [0.   0.   0.   0.   0.   0.45 0.   0.   0.55]\n [0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n [0.   0.   0.   0.   0.   0.   0.55 0.45 0.  ]\n [0.   0.   0.   0.   0.   0.   0.   0.55 0.45]]\nValue function by inverse:\n [-1.6667  0.7724  3.3333 -2.561  -3.4513  0.5564 -5.     -0.122  -2.4717]\nValue function by policy evaluation:\n [-1.6667  0.7724  3.3333 -2.561  -3.4513  0.5564 -5.     -0.122  -2.4717]\n"
    }
   ],
   "source": [
    "n = 3\n",
    "psucc = np.round(np.random.uniform(),2)\n",
    "# generating a random policy\n",
    "u = genRandSDP(n*n, k)\n",
    "# generating an MDP\n",
    "(Pk, R) = createMDP(n , psucc)\n",
    "P = getProbTranMat(Pk, u)\n",
    "\n",
    "print(\"Probability Transition Matrix:\\n\", P)\n",
    "print(\"Value function by inverse:\\n\", np.round(valueViaInv(P, 0.4, R), 4))\n",
    "print(\"Value function by policy evaluation:\\n\", np.round(valueEval(R, P, 0.4), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomWalk(L, P, R):\n",
    "    '''\n",
    "        Args:\n",
    "            L : length of the trajectory\n",
    "            P : transition probability matrix\n",
    "            R : reward mapping\n",
    "        Return:\n",
    "            A list containing tuples (s, r, s_next)\n",
    "            where s is the initial state, and\n",
    "            s_next is the state after transition\n",
    "            and r is the reward that we recived.\n",
    "    '''\n",
    "    rw = []\n",
    "    num_states = R.shape[0]\n",
    "    s = np.random.randint(n)\n",
    "\n",
    "    for i in range(L):\n",
    "        s_next = np.random.choice(num_states, p=P[s, :])\n",
    "        r = R[s_next]\n",
    "        rw.append((s, r, s_next))\n",
    "        s = s_next\n",
    "    \n",
    "    return rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Probability Transition Matrix:\n [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\nReward Mapping:\n [ 2  0 -3 -3 -2  0 -2 -1 -3]\nRandom Walk:\n [(1, 0, 1), (1, 0, 1), (1, 0, 1), (1, 0, 1), (1, 0, 1), (1, 0, 1), (1, 0, 1), (1, 0, 1), (1, 0, 1), (1, 0, 1)]\n"
    }
   ],
   "source": [
    "n = 3\n",
    "psucc = np.round(np.random.uniform(),2)\n",
    "# generating a random policy\n",
    "u = genRandSDP(n*n, k)\n",
    "# generating an MDP\n",
    "(Pk, R) = createMDP(n , psucc)\n",
    "P = getProbTranMat(Pk, u)\n",
    "\n",
    "print(\"Probability Transition Matrix:\\n\", P)\n",
    "print(\"Reward Mapping:\\n\", R)\n",
    "print(\"Random Walk:\\n\", randomWalk(10, P, R))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distribution(P, R, eps=1e-6, iter=10e5):\n",
    "    '''\n",
    "        Args:\n",
    "            P : transition probability matrix - n*n\n",
    "            R : reward mapping\n",
    "        Return:\n",
    "            d : vector representing the stationary \n",
    "                distribution\n",
    "    '''\n",
    "    L = P.shape[0]*3\n",
    "    err = np.inf\n",
    "\n",
    "    d = np.zeros(P.shape[0], dtype=np.float)\n",
    "    s = np.zeros(P.shape[0], dtype=np.int)\n",
    "    n = 0\n",
    "\n",
    "    while err > eps and iter >= 0:\n",
    "        iter -=1\n",
    "        rw = randomWalk(L, P, R)\n",
    "        d_new = copy.copy(d)\n",
    "        for (s, _ , s_next) in rw:\n",
    "            n += 1\n",
    "            one_hot = np.zeros(P.shape[0], dtype=np.int)\n",
    "            one_hot[s] = 1\n",
    "            d_new = ((n-1)*d + one_hot)/(n)\n",
    "        \n",
    "        err = np.linalg.norm(d_new - d, np.inf)\n",
    "        d = d_new\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Stationary Distribution:  [0.         0.         0.21334216 0.11851953 0.         0.\n 0.         0.         0.        ]\nd.P :  [0.         0.         0.21334216 0.11851953 0.         0.\n 0.         0.         0.        ]\n"
    }
   ],
   "source": [
    "n = 3\n",
    "psucc = np.round(np.random.uniform(),2)\n",
    "# generating a random policy\n",
    "u = genRandSDP(n*n, k)\n",
    "# generating an MDP\n",
    "(Pk, R) = createMDP(n , psucc)\n",
    "P = getProbTranMat(Pk, u)\n",
    "\n",
    "d = stationary_distribution(P, R)\n",
    "\n",
    "print(\"Stationary Distribution: \", d)\n",
    "print(\"d.P : \", np.dot(d,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
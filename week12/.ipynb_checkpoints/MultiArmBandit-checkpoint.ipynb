{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliBandit(object):\n",
    "    def __init__(self , k=5 , probas=None):\n",
    "        self.k = k\n",
    "        np.random.seed(int(time.time()))\n",
    "        if probas == None:\n",
    "            self.reward_probabilities = [ round(np.random.uniform(low=0.1 , high=0.9) , 2) \n",
    "                                         for i in range(k) ]\n",
    "        else:\n",
    "            self.reward_probabilities = probas\n",
    "            \n",
    "        self.best_probability = max(self.reward_probabilities)\n",
    "    \n",
    "    def print_bandit(self):\n",
    "        print(\"Reward Probabilities: {}\\nBest Probability: {}\"\n",
    "              .format(self.reward_probabilities, self.best_probability))\n",
    "    \n",
    "    def get_reward(self , i):\n",
    "        if np.random.random() >= self.reward_probabilities[i]:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedy(object):\n",
    "    def __init__(self, Bandit:BernoulliBandit , eps=1e-4):\n",
    "        assert(isinstance(Bandit, BernoulliBandit))\n",
    "        self.bandit = copy.deepcopy(Bandit)\n",
    "        self.epsilon = eps\n",
    "        self.action_val = np.zeros_like(self.bandit.reward_probabilities)\n",
    "        self.action_n = np.zeros_like(self.bandit.reward_probabilities , dtype=np.int)\n",
    "        \n",
    "    def run_one_step(self):\n",
    "        # choose an action\n",
    "        if np.random.random() > self.epsilon:\n",
    "            a_t = np.argmax(self.action_val)\n",
    "        else:\n",
    "            a_t = np.random.randint(low=0 , high=self.bandit.k)\n",
    "        \n",
    "        # get reward from the bandit\n",
    "        r = self.bandit.get_reward(a_t)\n",
    "        # update the action value\n",
    "        self.action_val[a_t] = (self.action_val[a_t] * self.action_n[a_t] + r ) / (self.action_n[a_t] + 1)\n",
    "        # update the number of times an action has been chosen\n",
    "        self.action_n[a_t] = self.action_n[a_t] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB(object):\n",
    "    def __init__(self, Bandit):\n",
    "        assert(isinstance(Bandit , BernoulliBandit))\n",
    "        self.bandit = copy.deepcopy(Bandit)\n",
    "        self.action_val = np.zeros_like(self.bandit.reward_probabilities)\n",
    "        self.action_n = np.zeros_like(self.bandit.reward_probabilities , dtype=np.int)\n",
    "        \n",
    "    def run_one_step(self):\n",
    "        # choose an action\n",
    "        \n",
    "        \n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

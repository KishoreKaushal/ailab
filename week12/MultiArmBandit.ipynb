{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliBandit(object):\n",
    "    def __init__(self , k=5 , probas=None):\n",
    "        self.k = k\n",
    "        np.random.seed(int(time.time()))\n",
    "        if probas == None:\n",
    "            self.reward_probabilities = [ round(np.random.uniform(low=0.1 , high=0.9) , 2) \n",
    "                                         for i in range(k) ]\n",
    "        else:\n",
    "            self.reward_probabilities = probas\n",
    "            \n",
    "        self.best_probability = max(self.reward_probabilities)\n",
    "    \n",
    "    def print_bandit(self):\n",
    "        print(\"Reward Probabilities: {}\\nBest Probability: {}\"\n",
    "              .format(self.reward_probabilities, self.best_probability))\n",
    "    \n",
    "    def get_reward(self , i):\n",
    "        if np.random.random() <= self.reward_probabilities[i]:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedy(object):\n",
    "    def __init__(self, Bandit:BernoulliBandit , eps=1e-4):\n",
    "        assert(isinstance(Bandit, BernoulliBandit))\n",
    "        self.bandit = copy.deepcopy(Bandit)\n",
    "        self.epsilon = eps\n",
    "        self.action_val = np.zeros_like(self.bandit.reward_probabilities)\n",
    "        self.action_count = np.zeros_like(self.bandit.reward_probabilities , dtype=np.int)\n",
    "        self.t = 0\n",
    "        \n",
    "    def run_one_step(self):\n",
    "        self.t+=1\n",
    "        # choose an action\n",
    "        if np.random.random() > self.epsilon:\n",
    "            a_t = np.argmax(self.action_val)\n",
    "        else:\n",
    "            a_t = np.random.randint(low=0 , high=self.bandit.k)\n",
    "        \n",
    "        # get reward from the bandit\n",
    "        r = self.bandit.get_reward(a_t)\n",
    "        # update the action value\n",
    "        self.action_val[a_t] = (self.action_val[a_t] * self.action_count[a_t] + r ) / (self.action_count[a_t] + 1)\n",
    "        # update the number of times an action has been chosen\n",
    "        self.action_count[a_t] = self.action_count[a_t] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB(object):\n",
    "    def __init__(self, Bandit):\n",
    "        assert(isinstance(Bandit , BernoulliBandit))\n",
    "        self.bandit = copy.deepcopy(Bandit)\n",
    "        self.action_val = np.zeros_like(self.bandit.reward_probabilities)\n",
    "        self.action_count = np.zeros_like(self.bandit.reward_probabilities , dtype=np.int)\n",
    "        self.t = 0\n",
    "            \n",
    "    def run_one_step(self):\n",
    "        self.t+=1\n",
    "        # choose an action\n",
    "        a_t = max(range(self.bandit.k) , key = lambda x: self.action_val[x] \n",
    "                              + np.sqrt( (2*np.log(self.t)) / (self.action_count[x]+1) ))\n",
    "        # get reward from the bandit\n",
    "        r = self.bandit.get_reward(a_t)\n",
    "        # update the action value\n",
    "        self.action_val[a_t] = (self.action_val[a_t] * self.action_count[a_t] + r ) / (self.action_count[a_t] + 1)\n",
    "        self.action_count[a_t] = self.action_count[a_t] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Probabilities: [0.78, 0.8, 0.24, 0.2, 0.75]\n",
      "Best Probability: 0.8\n"
     ]
    }
   ],
   "source": [
    "Bandit = BernoulliBandit()\n",
    "Bandit.print_bandit()\n",
    "ucb = UCB(Bandit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimates: [0.78190389 0.80105496 0.20967742 0.10869565 0.75472358]\n",
      "Action Count: [17396 76780    62    46  5716]\n",
      "Steps: 100000\n"
     ]
    }
   ],
   "source": [
    "steps = 100000\n",
    "while steps>0:\n",
    "    steps-=1\n",
    "    ucb.run_one_step()\n",
    "    \n",
    "print(\"Estimates: {}\".format(ucb.action_val))\n",
    "print(\"Action Count: {}\".format(ucb.action_count))\n",
    "print(\"Steps: {}\".format(ucb.t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
